{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 2: Feature Design / hand-designed features  \n",
    "Traditional ML Pipeline:  \n",
    "Convert Node/Edge/Graph to a vector and apply the model(Random forest/SVM/Nerual network)\n",
    "\n",
    "We focus on undirected graph.\n",
    "\n",
    "---\n",
    "## Lecture 2.1: Node Level Tasks\n",
    "* Node feature( ex). Color of node)\n",
    "    * Node degree\n",
    "    * Node centrality (need to consider node importance)\n",
    "        * Eigenvector centrality\n",
    "            * $c_v = \\frac{1}{\\lambda}\\sum_{N(v)} c_u$, or $\\lambda c=Ac$.\n",
    "            * The leading eigenvector is used.\n",
    "                * The largest eigenvalue is always positive.\n",
    "        * Betweenness centrality\n",
    "            * $c_v=\\sum_{s \\neq v \\neq t} \\frac{\\#(\\text { shortest paths betwen } s \\text { and } t \\text { that contain } v \\text { ) }}{\\#(\\text { shortest paths between } s \\text { and } t \\text { ) }}$\n",
    "        * Closeness centrality\n",
    "            * $c_v=\\frac{1}{\\sum_{u \\neq v} \\text { shortest path length between } u \\text { and } v}$\n",
    "    * Clustering coefficient\n",
    "        * Measures how connected $v^{\\prime} s$ neighboring nodes are:\n",
    "        * $e_v=\\frac{\\text { \\#(edges among neighboring nodes) }}{\\left(\\begin{array}{c}k_v \\\\ 2\\end{array}\\right)} \\in[0,1]$\n",
    "    * Graphlets\n",
    "        * generalization of the clustering coeff.(#(triangle))\n",
    "        * Graphlets: Rooted connected non-isomorphic subgraphs\n",
    "        * GDV(Graphlet Degree Vector) counts \\#(graphlets) that a node touches\n",
    "            * Degree counts \\#(edges) that a node touches\n",
    "            * Clustering coefficient counts \\#(triangles) that a node touches.\n",
    "        * After fixing a list of graphlets, get a vector.\n",
    "\n",
    "![image](src/cs224w_2.png)\n",
    "---\n",
    "- Importance-based feature:\n",
    "    - Node degree\n",
    "    - Different node centrality measures\n",
    "- Structure-based features:\n",
    "    - Node degree\n",
    "    - Clustering coefficient\n",
    "    - Graphlet count vector\n",
    "---\n",
    "## Lecture 2.2: Link-level Prediction Task\n",
    "* Links missing at random\n",
    "    * Remove a random set of links and then aim to predict them\n",
    "* Liks over time\n",
    "    * Given $G\\left[t_0, t_0^{\\prime}\\right]$ a graph on edges up to timet $t_0^{\\prime}$, output a ranked list $L$ of links (not in $\\left.G\\left[t_0, t_0^{\\prime}\\right]\\right)$ that are predicted to appear in $G\\left[t_1, t_1^{\\prime}\\right]$\n",
    "        * Evaluation:\n",
    "            - $n=\\left|E_{\\text {new }}\\right|$ : \\# new edges that appear during the test period $\\left[t_1, t_1^{\\prime}\\right]$\n",
    "            - Take top $n$ elements of $L$ and count correct edges\n",
    "---\n",
    "* Distance-based feature\n",
    "    * Shortest path distance between two nodes\n",
    "* Local Neighbor hood overlap\n",
    "    * Common neighbors\n",
    "        * $\\left|N\\left(v_1\\right) \\cap N\\left(v_2\\right)\\right|$\n",
    "    * Jaccard's coefficient\n",
    "        * Normalized version\n",
    "        * $\\frac{\\left|N\\left(v_1\\right) \\cap N\\left(v_2\\right)\\right|}{\\left|N\\left(v_1\\right) \\cup N\\left(v_2\\right)\\right|}$\n",
    "    * Adamic-Adar index\n",
    "        * $\\sum_{u \\in N\\left(v_1\\right) \\cap N\\left(v_2\\right)} \\frac{1}{\\log \\left(k_u\\right)}$\n",
    "* Global neighborhood overlap\n",
    "    * Limitation of local neighborhood features(too narrow)\n",
    "    * Katz index: count the number of paths of all lengths betwwen a given pair of nodes.\n",
    "        * Powers of Adj matrices\n",
    "        * $S_{v_1 v_2}=\\sum_{l=1}^{\\infty} \\beta^l \\boldsymbol{A}_{v_1 v_2}^l$\n",
    "            * $0<\\beta < 1$ : discount factor\n",
    "            * $S = \\sum_{i=1}^{\\infty} \\beta^i \\boldsymbol{A}^i=(\\boldsymbol{I}-\\beta \\boldsymbol{A})^{-1}-\\boldsymbol{I}$\n",
    "---\n",
    "## Lecture 2.3: Graph-level Features\n",
    "### Kernel Methods\n",
    "* Kernel $K\\left(G, G^{\\prime}\\right) \\in \\mathbb{R}$ measures similarity b/w data\n",
    "* Kernel matrix $\\boldsymbol{K}=\\left(K\\left(G, G^{\\prime}\\right)\\right)_{G, G^{\\prime}}$ must always be positive semidefinite (i.e., has positive eigenvals)\n",
    "    * There exists a feature representation $\\phi(\\cdot)$ such that $K\\left(G, G^{\\prime}\\right)=\\phi(G)^{\\mathrm{T}} \\phi\\left(G^{\\prime}\\right)$\n",
    "* Once the kernel is defined, off-the-shelf ML model, such as kernel SVM, can be used to make predictions.\n",
    "\n",
    "Key Idea: Bag-of-Words(BoW) for a graph  \n",
    "Ex: Bag of node degrees (#1, #2, #3)\n",
    "\n",
    "* Graphlet Features\n",
    "    * Count the number of different graphlets in a graph.\n",
    "        * Definition is slightly different from node-level features.\n",
    "            * not rooted / disconnected\n",
    "    * Given a graphlet list, define the graphlet count vector.\n",
    "    * $K(G, G')$: inner product of the vectors.\n",
    "    * Problems\n",
    "        * if $G$ and $G^{\\prime}$ have different sizes, that will greatly skew the value.\n",
    "            * Solution: normalize each feature vector\n",
    "            $\n",
    "            \\boldsymbol{h}_G=\\frac{\\boldsymbol{f}_G}{\\operatorname{Sum}\\left(\\boldsymbol{f}_G\\right)} \\quad K\\left(G, G^{\\prime}\\right)=\\boldsymbol{h}_G{ }^{\\mathrm{T}} \\boldsymbol{h}_{G^{\\prime}}\n",
    "            $\n",
    "        * Counteing graphlets is very expensive.(NP-hard)\n",
    "* Weisfeiler-Lehman Kernel\n",
    "    * Also known as color refinement\n",
    "    * Goal: design an efficient graph feature descriptor\n",
    "    * Use neighborhood structure to iteratively enrich node vocab.\n",
    "        * Assign an initial color $c^{(0)}(v)$ to each node $v$.\n",
    "        * $c^{(k+1)}(v)=\\operatorname{HASH}\\left(\\left\\{c^{(k)}(v),\\left\\{c^{(k)}(u)\\right\\}_{u \\in N(v)}\\right\\}\\right)$\n",
    "    * After (several) color refinement, WL kernel counts number of nodes with a given color, and get a vector.\n",
    "    * Use the dot product btw them.\n",
    "    * O(#(edges)) for each step"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
